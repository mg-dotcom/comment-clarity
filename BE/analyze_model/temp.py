# scrap
from selenium import  webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
import time, re
import bs4
import pandas as pd
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from dateutil.relativedelta import relativedelta

# model sentiment
from sklearn.preprocessing import LabelEncoder
import emoji
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus import thai_words
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import joblib
from xgboost import XGBClassifier


def analyze(link_url, start_date, end_date):
    # ‡πÉ‡∏ä‡πâ URL ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ URL ‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    url = link_url
    
    def open_driver():
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        options.add_argument("--headless")  # ‡πÄ‡∏û‡∏¥‡πà‡∏° headless mode ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")  # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÉ‡∏ô Docker
        options.add_argument("--disable-gpu")     # ‡∏õ‡∏¥‡∏î GPU acceleration
        options.add_argument("--enable-unsafe-swiftshader")  # ‡πÉ‡∏ä‡πâ SwiftShader ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå

        try:
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
            return driver
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô driver: {e}")
            return None

    # ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (YYYY-MM)
        start_period = start_date
        if len(start_period.split('-')[1]) == 1:  # ‡πÄ‡∏ä‡πà‡∏ô 2025-5
            month = start_period.split('-')[1].zfill(2)
            start_period = f"{start_period.split('-')[0]}-{month}"
            
        end_period = end_date
        if len(end_period.split('-')[1]) == 1:  # ‡πÄ‡∏ä‡πà‡∏ô 2025-5
            month = end_period.split('-')[1].zfill(2)
            end_period = f"{end_period.split('-')[0]}-{month}"
            
        print(f"üîÑ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: {start_period} ‡∏ñ‡∏∂‡∏á {end_period}")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {e}")
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        start_period = "2025-5"
        end_period = "2025-05"


    # ‡πÅ‡∏õ‡∏•‡∏á start_period ‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏ö 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    try:
        start_dt = datetime.strptime(start_period, "%Y-%m")
        stop_dt = start_dt - relativedelta(months=1)
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô string ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö YYYY-MM
        stop_period = stop_dt.strftime("%Y-%m")
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: {e}")
        # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        stop_period = "2025-04"  # ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å 2025-05

        next_button = "/html/body/div[5]/div/div[10]/div[1]/div[2]/div/div/div/div[3]/div[2]/div/button[2]" #‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        sort_button_xpath = "/html/body/div[5]/div/div[10]/div[1]/div[2]/div/div/div/div[2]/div/div[2]" #‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
        newest_first_option_xpath = "/html/body/div[9]/div/div/ul/li[2]" #‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (fix lazy loading)
    def scroll_to_bottom(driver):
        try:
            prev_height = 0
            max_attempts = 5  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô
            attempts = 0
            
            while attempts < max_attempts:
                driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(1)
                new_height = driver.execute_script("return window.scrollY + window.innerHeight")
                page_height = driver.execute_script("return document.body.scrollHeight")
                if new_height >= page_height:
                    break
                attempts += 1
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤: {e}")

    #click element with better error handling
    def click_element(driver, xpath, max_attempts=3):
        attempts = 0
        while attempts < max_attempts:
            try:
                element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath)))
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                driver.execute_script("arguments[0].click();", element)
                time.sleep(1)
                return True
            except Exception as e:
                print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ó‡∏µ‡πà xpath {xpath}: {e}")
                attempts += 1
                time.sleep(1)
        
        return False

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå
    driver = open_driver()
    if not driver:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ")
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
    
    try:
        driver.get(url)
        time.sleep(3)
        scroll_to_bottom(driver)  # Scroll ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ element ‡πÇ‡∏´‡∏•‡∏î
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î URL ‡πÑ‡∏î‡πâ: {e}")
        driver.quit()
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    max_attempts = 3
    attempts = 0
    sort_button_found = False
    
    while attempts < max_attempts and not sort_button_found:
        try:
            # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏õ‡∏∏‡πà‡∏° Sort ‡∏õ‡∏£‡∏≤‡∏Å‡∏è
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, sort_button_xpath)))
            print("‚úÖ ‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏° Sort")
            sort_button_found = True
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏° Sort (‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempts+1}/{max_attempts}): {e}")
            driver.quit()  # ‡∏õ‡∏¥‡∏î driver
            driver = open_driver()  # ‡πÄ‡∏õ‡∏¥‡∏î driver ‡πÉ‡∏´‡∏°‡πà
            if not driver:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ")
                return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
            
            driver.get(url)
            time.sleep(3)
            scroll_to_bottom(driver)
            attempts += 1
    
    if not sort_button_found:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° Sort ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
        driver.quit()
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    # ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    if not click_element(driver, sort_button_xpath):
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏° Sort ‡πÑ‡∏î‡πâ")
        driver.quit()
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
    
    if not click_element(driver, newest_first_option_xpath):
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏î‡πâ")
        driver.quit()
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    thai_months = {"‡∏°.‡∏Ñ.": "01", "‡∏Å.‡∏û.": "02", "‡∏°‡∏µ.‡∏Ñ.": "03", "‡πÄ‡∏°.‡∏¢.": "04", "‡∏û.‡∏Ñ.": "05", "‡∏°‡∏¥.‡∏¢.": "06", 
                  "‡∏Å.‡∏Ñ.": "07", "‡∏™.‡∏Ñ.": "08", "‡∏Å.‡∏¢.": "09", "‡∏ï.‡∏Ñ.": "10", "‡∏û.‡∏¢.": "11", "‡∏ò.‡∏Ñ.": "12"}

    def to_full_date(text):
        try:
            now = datetime.now()
            if "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á" in text:
                hours = int(re.search(r'\d+', text).group()) if re.search(r'\d+', text) else 1
                dt = now - timedelta(hours=hours)
            elif "‡∏ß‡∏±‡∏ô" in text:
                days = int(re.search(r'\d+', text).group()) if re.search(r'\d+', text) else 1
                dt = now - timedelta(days=days)
            elif "‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå" in text:
                weeks = int(re.search(r'\d+', text).group()) if re.search(r'\d+', text) else 1
                dt = now - timedelta(weeks=weeks)
            elif "‡∏ô‡∏≤‡∏ó‡∏µ" in text:
                minutes = int(re.search(r'\d+', text).group()) if re.search(r'\d+', text) else 1
                dt = now - timedelta(minutes=minutes)
            elif "‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ" in text:
                seconds = int(re.search(r'\d+', text).group()) if re.search(r'\d+', text) else 1
                dt = now - timedelta(seconds=seconds)
            else:
                parts = text.split()
                if len(parts) == 3:
                    day = parts[0]
                    month = thai_months.get(parts[1], None)
                    year = parts[2]
                    if month:
                        date_str = f"{year}-{month}-{day.zfill(2)}"
                        try:
                            dt = datetime.strptime(date_str, "%Y-%m-%d")
                            return dt.strftime("%Y-%m-%d")
                        except:
                            return None
                return None
            return dt.strftime("%Y-%m-%d")
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {e}")
            return None

    def is_within_period(month_year, start_period, end_period):
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏)
        return start_period <= month_year <= end_period

    def click_next_button():
        try:
            next_button = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, "/html/body/div[5]/div/div[10]/div[1]/div[2]/div/div/div/div[3]/div[2]/div/button[2]"))
            )
            driver.execute_script("arguments[0].click();", next_button)
            time.sleep(2)
            return True
        except Exception as e:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÑ‡∏î‡πâ: {e}")
            return False

    all_reviews = []
    print("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß...")

    max_pages = 100  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô infinite loop
    page_count = 0
    
    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    found_target_month = False
    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏´‡∏°‡∏î‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    past_target_period = False
    
    while page_count < max_pages:
        page_count += 1
        print(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {page_count}")
        
        try:
            soup = BeautifulSoup(driver.page_source, "html.parser")
            date_spans = soup.find_all("span", class_="title right")

            if not date_spans:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")
                break

            reviews_found_on_page = False
            date_to_review_map = []

            # ‡∏´‡∏≤‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
            content_divs = [
                content
                for item in soup.find_all('div', class_='item-content')
                if item.get('class') == ['item-content']
                for content in item.find_all('div', class_='content')
            ]
            
            star_divs = soup.find_all('div', class_='container-star starCtn left')
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß content ‡πÅ‡∏•‡∏∞ star_divs ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if len(content_divs) != len(star_divs) or len(content_divs) != len(date_spans):
                print(f"‚ö†Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô: Content: {len(content_divs)}, Stars: {len(star_divs)}, Dates: {len(date_spans)}")
                # ‡πÉ‡∏ä‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                min_length = min(len(content_divs), len(star_divs), len(date_spans))
                content_divs = content_divs[:min_length]
                star_divs = star_divs[:min_length]
                date_spans = date_spans[:min_length]

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            reviews_data = []
            for idx, (content_div, star_div, date_span) in enumerate(zip(content_divs, star_divs, date_spans)):
                raw_text = content_div.get_text(strip=True)
                raw_date = date_span.get_text(strip=True)
                
                full_date = to_full_date(raw_date)
                if not full_date:
                    continue
                
                month_year = full_date[:7] if full_date else None
                if not month_year:
                    continue
                
                # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏î‡∏≤‡∏ß
                rating = len([img for img in star_div.find_all('img', class_='star') 
                           if img.get('src') == "//img.lazcdn.com/g/tps/tfs/TB19ZvEgfDH8KJjy1XcXXcpdXXa-64-64.png"])
                
                reviews_data.append({
                    "text": raw_text,
                    "date": full_date,
                    "month_year": month_year,
                    "rating": rating
                })

            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            current_page_has_target_month = False
            
            for review_data in reviews_data:
                month_year = review_data["month_year"]
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if start_period <= month_year <= end_period:
                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                    all_reviews.append({
                        "ratings": review_data["rating"],
                        "text": review_data["text"],
                        "date": review_data["date"]
                    })
                    found_target_month = True
                    current_page_has_target_month = True
                    reviews_found_on_page = True
                elif month_year < start_period:
                    # ‡πÄ‡∏à‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
                    past_target_period = True
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if current_page_has_target_month:
                print(f"‚úÖ ‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")
            else:
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")
            
            # ‡∏´‡∏¢‡∏∏‡∏î‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡∏≤‡πÄ‡∏à‡∏≠‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏à‡∏≠‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
            if past_target_period and found_target_month:
                print("‚úÖ ‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏•‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£")
                break
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏à‡∏≠‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏¢
            # ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏≠‡∏µ‡∏Å‡∏™‡∏±‡∏Å‡∏´‡∏ô‡πâ‡∏≤ (‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)
            if past_target_period and not found_target_month and page_count < 3:
                print("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ï‡πà‡πÄ‡∏à‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡πà‡∏≠‡∏≠‡∏µ‡∏Å‡∏´‡∏ô‡πâ‡∏≤")
                
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢
            if not reviews_found_on_page:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")
                
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÉ‡∏´‡∏°‡πà ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î
                if past_target_period:
                    print("üõë ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÅ‡∏•‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß")
                    break

            # ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
            if not click_next_button():
                print("üõë ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏° Next ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
                break
                
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ {page_count}: {e}")
            break

    # ‡∏õ‡∏¥‡∏î driver
    try:
        driver.quit()
    except:
        pass

    print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(all_reviews)}")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏à‡∏≤‡∏Å‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏î‡πâ
    df = pd.DataFrame(all_reviews)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ DataFrame ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if df.empty:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏µ‡∏ß‡∏¥‡∏ß")
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text' ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if 'text' not in df.columns:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text' ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        print("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ:", df.columns.tolist())
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    try:
        VOCAB = set(thai_words())

        def clean_tokenize(text):
            text = emoji.replace_emoji(text, '').replace('\n', ' ').replace('\r', ' ') #‡∏•‡∏ö emoji ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà
            text = re.sub(r'(.)\1{3,}', r'\1\1', text)  # ‡∏ï‡∏±‡∏î‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ã‡πâ‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏ï‡∏±‡∏ß
            text = re.sub(r'[^\u0E00-\u0E7Fa-zA-Z0-9\s:]', '', text)  # ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©
            seen = set()
            text = " ".join([w for w in text.split() if not (w in seen or seen.add(w))])  # ‡∏•‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏≥‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå
            tokens = word_tokenize(text, engine="newmm", keep_whitespace=True) #tokenize
            return [w for w in tokens if w in VOCAB or w.isnumeric()] #‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥

        def safe_clean(text):
            try:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
                if isinstance(text, str):
                    return clean_tokenize(text)
                else:
                    return None  # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏™‡∏ï‡∏£‡∏¥‡∏á
            except Exception as e:
                print(f"Error processing row: {e}")  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ
                return None  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠
            
        if 'text' in df.columns:
            df["text_tokens"] = df["text"].apply(safe_clean)  # ‡πÄ‡∏Å‡πá‡∏ö tokens ‡πÅ‡∏¢‡∏Å
            df = df[~df['text_tokens'].isin(['[]', '', None])]  # ‡∏Å‡∏£‡∏≠‡∏á rows ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ tokens
            # ‡πÅ‡∏õ‡∏•‡∏á tokens ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö CountVectorizer
            df["text_processed"] = df["text_tokens"].apply(lambda x: ' '.join(x) if x else '')
        else:
            print("Error: 'text' column does not exist in the DataFrame.")
            return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])

    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    models_loaded = True
    model_files = ['cvec.pkl', 'le_sentiment.pkl', 'xgb_sentiment.pkl', 'le_category.pkl', 'xgb_category.pkl']
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for model_file in model_files:
        if not os.path.exists(model_file):
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_file}")
            models_loaded = False
    
    if not models_loaded:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå")
        return df[['ratings', 'text', 'date']]  # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô DataFrame ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        
    try:
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
        cvec = joblib.load('cvec.pkl')
        le_sentiment = joblib.load('le_sentiment.pkl')
        le_category = joblib.load('le_category.pkl')
        
        xgb_sentiment = XGBClassifier()
        xgb_sentiment.load_model('xgb_sentiment.json')
        xgb_category = XGBClassifier()
        xgb_category.load_model('xgb_category.json')

        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß")

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥ vectorize
        print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {len(df)}")
        
        if len(df) == 0:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")
            return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
            
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ vectorize
        feature_column = 'text'
        if 'text_processed' in df.columns:
            feature_column = 'text_processed'
            
        print(f"üîÑ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{feature_column}' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö vectorize")
            
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥ vectorize ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        try:
            sample_size = min(5, len(df))
            print(f"üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏≥ vectorize ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {sample_size} ‡πÅ‡∏ñ‡∏£‡∏Å‡πÅ‡∏£‡∏Å")
            sample_data = df[feature_column][:sample_size].fillna('')
            X_sample = cvec.transform(sample_data)
            print(f"‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: Vector shape: {X_sample.shape}")
        except Exception as e:
            print(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö vectorize ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
            print("üîÑ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text' ‡πÅ‡∏ó‡∏ô")
            feature_column = 'text'
            sample_data = df[feature_column][:sample_size].fillna('')
            X_sample = cvec.transform(sample_data)

        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢...")
        X = cvec.transform(df[feature_column].fillna(''))
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå 
        sentiment_pred = xgb_sentiment.predict(X)
        df['sentimentType'] = le_sentiment.inverse_transform(sentiment_pred)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô
        category_pred = xgb_category.predict(X)
        df['commentCategoryName'] = le_category.inverse_transform(category_pred)
        
        print("‚úÖ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å
        result_df = df[['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName']]

        print("üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô:")
        print(result_df) 
        return result_df
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: {e}")
        # ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô DataFrame ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
        if 'ratings' in df.columns and 'text' in df.columns and 'date' in df.columns:
            return df[['ratings', 'text', 'date']]
        else:
            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
            return pd.DataFrame(columns=['ratings', 'text', 'date', 'sentimentType', 'commentCategoryName'])
        
if __name__ == "__main__":
    link_url = "https://www.lazada.co.th/products/3-i5432338284-s23195260672.html?pvid=95e452bf-d588-4c34-bec7-f84bf9de8bdc&search=jfy&scm=1007.45039.432958.0&priceCompare=skuId%3A23195260672%3Bsource%3Atpp-recommend-plugin-32104%3Bsn%3A95e452bf-d588-4c34-bec7-f84bf9de8bdc%3BoriginPrice%3A5900%3BdisplayPrice%3A5900%3BsinglePromotionId%3A-1%3BsingleToolCode%3AmockedSalePrice%3BvoucherPricePlugin%3A0%3Btimestamp%3A1746879709497&spm=a2o4m.homepage.just4u.d_5432338284" 
    start_period = "2025-5"
    end_period = "2025-05"
    result = analyze(link_url, start_period, end_period)
    print(result)